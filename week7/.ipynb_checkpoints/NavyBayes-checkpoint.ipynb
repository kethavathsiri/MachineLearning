{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83eac578-022e-4026-a237-2480f79fc547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d331b679-4888-457f-8f95-475ab6373e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##2.Load 20 Newsgroups dataset\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cca09fca-e56b-4bdb-a90d-4096fe53c8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"categories = ['alt.atheism', 'comp.graphics', 'sci.space']\\nnewsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\\nnewsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f7f5fbd-fb3d-417c-a5e1-eb6a4033ba73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: degroff@netcom.com (21012d)\\nSubject: Re...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: healta@saturn.wwc.edu (Tammy R Healy)\\nS...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: capelli@vnet.IBM.COM (Ron Capelli)\\nSubj...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: henry@zoo.toronto.edu (Henry Spencer)\\nS...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>From: renes@ecpdsharmony.cern.ch (Rene S. Dutc...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>From: xrcjd@resolve.gsfc.nasa.gov (Charles J. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>From: dietz@cs.rochester.edu (Paul Dietz)\\nSub...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>From: jhwitten@cs.ruu.nl (Jurriaan Wittenberg)...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1657 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target       category\n",
       "0     From: degroff@netcom.com (21012d)\\nSubject: Re...       2      sci.space\n",
       "1     From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...       1  comp.graphics\n",
       "2     From: healta@saturn.wwc.edu (Tammy R Healy)\\nS...       0    alt.atheism\n",
       "3     From: capelli@vnet.IBM.COM (Ron Capelli)\\nSubj...       1  comp.graphics\n",
       "4     From: henry@zoo.toronto.edu (Henry Spencer)\\nS...       2      sci.space\n",
       "...                                                 ...     ...            ...\n",
       "1652  From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...       1  comp.graphics\n",
       "1653  From: renes@ecpdsharmony.cern.ch (Rene S. Dutc...       1  comp.graphics\n",
       "1654  From: xrcjd@resolve.gsfc.nasa.gov (Charles J. ...       2      sci.space\n",
       "1655  From: dietz@cs.rochester.edu (Paul Dietz)\\nSub...       2      sci.space\n",
       "1656  From: jhwitten@cs.ruu.nl (Jurriaan Wittenberg)...       2      sci.space\n",
       "\n",
       "[1657 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.load 20news group train subest\n",
    "train_subset=pd.read_csv(\"newsgroups_train.csv\")\n",
    "train_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3cb27f5-1a46-4b56-83a5-96e82e39348b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: mccall@mksol.dseg.ti.com (fred j mccall ...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: \"Changyaw Wang\" &lt;wangc@cs.indiana.edu&gt;\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: lioness@maple.circa.ufl.edu\\nSubject: Te...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: hotopp@ami1.bwi.wec.com (Daniel T. Hotop...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: Ad-Robot@bobsbox.rent.com (Robotic Posti...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>From: malek@pi.titech.ac.jp (Zidouri Abdelmale...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>From: livesey@solntze.wpd.sgi.com (Jon Livesey...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>From: beck@irzr17.inf.tu-dresden.de (Andre Bec...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>From: 18084TM@msu.edu (Tom)\\nSubject: Billboar...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1102 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target       category\n",
       "0     From: mccall@mksol.dseg.ti.com (fred j mccall ...       2      sci.space\n",
       "1     From: \"Changyaw Wang\" <wangc@cs.indiana.edu>\\n...       1  comp.graphics\n",
       "2     From: lioness@maple.circa.ufl.edu\\nSubject: Te...       1  comp.graphics\n",
       "3     From: hotopp@ami1.bwi.wec.com (Daniel T. Hotop...       1  comp.graphics\n",
       "4     From: Ad-Robot@bobsbox.rent.com (Robotic Posti...       1  comp.graphics\n",
       "...                                                 ...     ...            ...\n",
       "1097  From: malek@pi.titech.ac.jp (Zidouri Abdelmale...       1  comp.graphics\n",
       "1098  From: livesey@solntze.wpd.sgi.com (Jon Livesey...       0    alt.atheism\n",
       "1099  From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...       0    alt.atheism\n",
       "1100  From: beck@irzr17.inf.tu-dresden.de (Andre Bec...       1  comp.graphics\n",
       "1101  From: 18084TM@msu.edu (Tom)\\nSubject: Billboar...       2      sci.space\n",
       "\n",
       "[1102 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4.load 20news group train subest\n",
    "test_subset=pd.read_csv(\"newsgroups_test.csv\")\n",
    "test_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09fc6960-0841-4da6-b002-8e7b2cb28adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All target labels in 20 Newsgroups dataset:\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "#5.print all # Load the dataset\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "\n",
    "# Print all target labels (categories)\n",
    "print(\"All target labels in 20 Newsgroups dataset:\")\n",
    "print(newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82dc2f07-be43-47ad-bd7d-4410e4bbf168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected categories: ['alt.atheism', 'comp.graphics', 'sci.space']\n",
      "\n",
      "Sample Text from Training Data:\n",
      " \n",
      "  I doubt there are good prospects for  a self armoring system\n",
      "for venus surface conditions (several hundred degrees, very high\n",
      "pressure of CO2, possibly sulfuric and nitric acids or oxides\n",
      "but it is a notion to consider for outer planets rs where you might\n",
      "pick up ices under less extream upper atmosphere conditions buying\n",
      "deeper penetration.  A nice creative idea, unlikly but worthy of\n",
      "thinking about.\n",
      "\n",
      "\n",
      "Corresponding Label: 2\n"
     ]
    }
   ],
   "source": [
    "#6.prepare subset of categories alt.athessm com.graphics sci.space\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the dataset with the selected categories\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Print the categories to confirm the subset\n",
    "print(\"Selected categories:\", newsgroups_train.target_names)\n",
    "\n",
    "# Print some sample data and labels\n",
    "print(\"\\nSample Text from Training Data:\\n\", newsgroups_train.data[0])\n",
    "print(\"\\nCorresponding Label:\", newsgroups_train.target[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1936fcb3-5b7a-4968-bb56-2ea78c5c1812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded categories: ['alt.atheism', 'comp.graphics', 'sci.space']\n"
     ]
    }
   ],
   "source": [
    "#7 Load the training subset with selected categories\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Print the selected categories\n",
    "print(\"Loaded categories:\", newsgroups_train.target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2592c831-f58e-42f6-94e9-8ac5f7e369b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded categories: ['alt.atheism', 'comp.graphics', 'sci.space']\n"
     ]
    }
   ],
   "source": [
    "#8 Load the test subset with selected categories\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Print the selected categories\n",
    "print(\"Loaded categories:\", newsgroups_test.target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5d0507f-e6f0-4c14-9915-682a518809fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New training set target names (labels): ['alt.atheism', 'comp.graphics', 'sci.space']\n",
      "Numerical labels assigned: {0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "#9.print new training set traget names(Lables)\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the training subset with selected categories\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Print the selected category labels\n",
    "print(\"New training set target names (labels):\", newsgroups_train.target_names)\n",
    "\n",
    "# Print unique numerical labels assigned to the categories\n",
    "print(\"Numerical labels assigned:\", set(newsgroups_train.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1d1bdc0-4209-489d-b67d-e67c2f51f5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - 5th Article:\n",
      "\n",
      "\n",
      "I don't think you're going to be able to see the differences from a sphere\n",
      "unless they are greatly exaggerated.  Even the equatorial bulge is only\n",
      "about 1 part in 300 -- you'd never notice a 1mm error in a 30cm globe --\n",
      "and the other deviations from spherical shape are much smaller.\n",
      "\n",
      "Label of 5th Article: 2\n",
      "Category Name: sci.space\n"
     ]
    }
   ],
   "source": [
    "#10.print new training data of 5th article\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the training subset with selected categories\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Print the 5th article's text\n",
    "print(\"Training Data - 5th Article:\\n\")\n",
    "print(newsgroups_train.data[4])  # Index 4 (since indexing starts at 0)\n",
    "\n",
    "# Print the corresponding label of the 5th article\n",
    "print(\"\\nLabel of 5th Article:\", newsgroups_train.target[4])\n",
    "print(\"Category Name:\", newsgroups_train.target_names[newsgroups_train.target[4]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49bcef5e-f32f-4286-b7f9-3af83fa7c77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: 1657\n",
      "Shape of training targets: 1657\n"
     ]
    }
   ],
   "source": [
    "#11.print the shape of data and targets\n",
    "print(\"Shape of training data:\", len(newsgroups_train.data))\n",
    "\n",
    "# Print the shape of the targets (number of labels)\n",
    "print(\"Shape of training targets:\", len(newsgroups_train.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "26f8fb34-f967-40de-aa1b-e2d7471252c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 training set filenames:\n",
      "['/home/user/scikit_learn_data/20news_home/20news-bydate-train/sci.space/60869'\n",
      " '/home/user/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38633'\n",
      " '/home/user/scikit_learn_data/20news_home/20news-bydate-train/alt.atheism/53534'\n",
      " '/home/user/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38516'\n",
      " '/home/user/scikit_learn_data/20news_home/20news-bydate-train/sci.space/61210']\n",
      "\n",
      "Total number of training files: 1657\n"
     ]
    }
   ],
   "source": [
    "#12. Print the first 5 filenames\n",
    "print(\"First 5 training set filenames:\")\n",
    "print(newsgroups_train.filenames[:5])\n",
    "\n",
    "# Print the total number of filenames\n",
    "print(\"\\nTotal number of training files:\", len(newsgroups_train.filenames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0adb267-ca46-4cc7-ae91-cdd99adfebb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of transformed training data (document-term matrix): (1657, 23598)\n",
      "\n",
      "Sample feature names: ['00' '000' '0000' '00000' '000000' '000005102000' '000062david42'\n",
      " '000100255pixel' '00041032' '0004136']\n",
      "\n",
      "Sample transformed data (word count vector for first document):\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#13.by using count vectorizer train data into numerical format considering\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the training subset\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data into numerical format\n",
    "X_train_counts = vectorizer.fit_transform(newsgroups_train.data)\n",
    "\n",
    "# Print the shape of transformed data\n",
    "print(\"Shape of transformed training data (document-term matrix):\", X_train_counts.shape)\n",
    "\n",
    "# Print some feature names (words converted to features)\n",
    "print(\"\\nSample feature names:\", vectorizer.get_feature_names_out()[:10])\n",
    "\n",
    "# Print a sample row of the transformed data\n",
    "print(\"\\nSample transformed data (word count vector for first document):\")\n",
    "print(X_train_counts[0].toarray())  # Convert sparse matrix to dense array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6267d4a5-9755-44e9-bc3f-32bb9bf48ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB Accuracy: 0.6987295825771325\n",
      "\n",
      "Predicted category for sample text: comp.graphics\n"
     ]
    }
   ],
   "source": [
    "#14\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the training and test subsets\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Convert text data into numerical format using CountVectorizer\n",
    "vectorizer = CountVectorizer(binary=True)  # BernoulliNB works well with binary features\n",
    "X_train_counts = vectorizer.fit_transform(newsgroups_train.data)\n",
    "X_test_counts = vectorizer.transform(newsgroups_test.data)\n",
    "\n",
    "# Initialize and train the Bernoulli Naïve Bayes classifier\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_counts, newsgroups_train.target)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = bnb.predict(X_test_counts)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(newsgroups_test.target, y_pred)\n",
    "print(\"BernoulliNB Accuracy:\", accuracy)\n",
    "\n",
    "# Predict the category of a sample document\n",
    "sample_text = [\"NASA is planning a new space mission.\"]\n",
    "sample_vectorized = vectorizer.transform(sample_text)\n",
    "predicted_category = newsgroups_train.target_names[bnb.predict(sample_vectorized)[0]]\n",
    "\n",
    "print(\"\\nPredicted category for sample text:\", predicted_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff7b570f-1ad9-485b-b5a8-a97c2248e987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of transformed test data (document-term matrix): (1102, 23598)\n",
      "\n",
      "Sample feature names: ['00' '000' '0000' '00000' '000000' '000005102000' '000062david42'\n",
      " '000100255pixel' '00041032' '0004136']\n",
      "\n",
      "Sample transformed test data (word count vector for first document):\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#15\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the training and test subsets\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Initialize CountVectorizer and fit only on training data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(newsgroups_train.data)  # Fit on training data\n",
    "\n",
    "# Transform test data using the same vocabulary\n",
    "X_test_counts = vectorizer.transform(newsgroups_test.data)  # Transform test data\n",
    "\n",
    "# Print the shape of transformed test data\n",
    "print(\"Shape of transformed test data (document-term matrix):\", X_test_counts.shape)\n",
    "\n",
    "# Print some feature names (words converted to features)\n",
    "print(\"\\nSample feature names:\", vectorizer.get_feature_names_out()[:10])\n",
    "\n",
    "# Print a sample row of the transformed test data\n",
    "print(\"\\nSample transformed test data (word count vector for first document):\")\n",
    "print(X_test_counts[0].toarray())  # Convert sparse matrix to dense array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "56de96b8-2b69-4680-b85e-386f537eba11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted target labels for test set:\n",
      " [2 1 1 ... 0 1 2]\n",
      "\n",
      "Actual target labels:\n",
      " [2 1 1 ... 0 1 2]\n",
      "\n",
      "BernoulliNB Accuracy on test set: 0.6987295825771325\n"
     ]
    }
   ],
   "source": [
    "#16\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the training and test subsets\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Convert text data into numerical format using CountVectorizer\n",
    "vectorizer = CountVectorizer(binary=True)  # BernoulliNB works better with binary features\n",
    "X_train_counts = vectorizer.fit_transform(newsgroups_train.data)  # Fit on training data\n",
    "X_test_counts = vectorizer.transform(newsgroups_test.data)  # Transform test data\n",
    "\n",
    "# Initialize and train the Bernoulli Naïve Bayes classifier\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_counts, newsgroups_train.target)\n",
    "\n",
    "# Predict target labels for the test set\n",
    "y_pred = bnb.predict(X_test_counts)\n",
    "\n",
    "# Print the predicted labels\n",
    "print(\"Predicted target labels for test set:\\n\", y_pred)\n",
    "\n",
    "# Print the actual labels for comparison\n",
    "print(\"\\nActual target labels:\\n\", newsgroups_test.target)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(newsgroups_test.target, y_pred)\n",
    "print(\"\\nBernoulliNB Accuracy on test set:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a35eb546-9a91-4585-9888-e5f61f769cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB Accuracy on test set: 0.6987295825771325\n"
     ]
    }
   ],
   "source": [
    "#17\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the training and test subsets\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Convert text data into numerical format using CountVectorizer\n",
    "vectorizer = CountVectorizer(binary=True)  # Binary word presence for BernoulliNB\n",
    "X_train_counts = vectorizer.fit_transform(newsgroups_train.data)  # Fit on training data\n",
    "X_test_counts = vectorizer.transform(newsgroups_test.data)  # Transform test data\n",
    "\n",
    "# Initialize and train the Bernoulli Naïve Bayes classifier\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_counts, newsgroups_train.target)\n",
    "\n",
    "# Predict target labels for the test set\n",
    "y_pred = bnb.predict(X_test_counts)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(newsgroups_test.target, y_pred)\n",
    "print(\"BernoulliNB Accuracy on test set:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bfacd20e-2ab6-4a21-8742-6ad2cba43fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy on test set: 0.8620689655172413\n"
     ]
    }
   ],
   "source": [
    "#18.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the training and test subsets\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Convert text data into numerical format using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(newsgroups_train.data)  # Fit on training data\n",
    "X_test_tfidf = vectorizer.transform(newsgroups_test.data)  # Transform test data\n",
    "\n",
    "# Initialize and train the Multinomial Naïve Bayes classifier\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, newsgroups_train.target)\n",
    "\n",
    "# Predict target labels for the test set\n",
    "y_pred = mnb.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(newsgroups_test.target, y_pred)\n",
    "print(\"MultinomialNB Accuracy on test set:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "60d16c09-3cd0-4d5a-8385-ce4195805bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy using TfidfVectorizer & MultinomialNB: 0.8620689655172413\n"
     ]
    }
   ],
   "source": [
    "#19\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the training and test subsets\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Convert text data into numerical format using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(newsgroups_train.data)  # Fit on training data\n",
    "X_test_tfidf = vectorizer.transform(newsgroups_test.data)  # Transform test data\n",
    "\n",
    "# Initialize and train the Multinomial Naïve Bayes classifier\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, newsgroups_train.target)\n",
    "\n",
    "# Predict target labels for the test set\n",
    "y_pred = mnb.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(newsgroups_test.target, y_pred)\n",
    "print(\"Test set accuracy using TfidfVectorizer & MultinomialNB:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0d7721fe-f2ef-4e0d-ac49-07952825ce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy using TfidfVectorizer (with stopword removal) & MultinomialNB: 0.8729582577132486\n"
     ]
    }
   ],
   "source": [
    "#20\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the training and test subsets\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Convert text data into numerical format using TfidfVectorizer (with stopword removal)\n",
    "vectorizer = TfidfVectorizer(stop_words='english')  # Removes common stopwords like \"the\", \"is\", \"and\"\n",
    "X_train_tfidf = vectorizer.fit_transform(newsgroups_train.data)  # Fit on training data\n",
    "X_test_tfidf = vectorizer.transform(newsgroups_test.data)  # Transform test data\n",
    "\n",
    "# Initialize and train the Multinomial Naïve Bayes classifier\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, newsgroups_train.target)\n",
    "\n",
    "# Predict target labels for the test set\n",
    "y_pred = mnb.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(newsgroups_test.target, y_pred)\n",
    "print(\"Test set accuracy using TfidfVectorizer (with stopword removal) & MultinomialNB:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1381c7-4ec2-4a9c-9fa2-c47c8eaa990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=input\n",
    "#y=categories "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
