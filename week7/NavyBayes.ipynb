{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "83eac578-022e-4026-a237-2480f79fc547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d331b679-4888-457f-8f95-475ab6373e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##2.Load 20 Newsgroups dataset\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cca09fca-e56b-4bdb-a90d-4096fe53c8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"categories = ['alt.atheism', 'comp.graphics', 'sci.space']\\nnewsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\\nnewsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\\n\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7f7f5fbd-fb3d-417c-a5e1-eb6a4033ba73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: degroff@netcom.com (21012d)\\nSubject: Re...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: healta@saturn.wwc.edu (Tammy R Healy)\\nS...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: capelli@vnet.IBM.COM (Ron Capelli)\\nSubj...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: henry@zoo.toronto.edu (Henry Spencer)\\nS...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>From: renes@ecpdsharmony.cern.ch (Rene S. Dutc...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>From: xrcjd@resolve.gsfc.nasa.gov (Charles J. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>From: dietz@cs.rochester.edu (Paul Dietz)\\nSub...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>From: jhwitten@cs.ruu.nl (Jurriaan Wittenberg)...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1657 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target       category\n",
       "0     From: degroff@netcom.com (21012d)\\nSubject: Re...       2      sci.space\n",
       "1     From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...       1  comp.graphics\n",
       "2     From: healta@saturn.wwc.edu (Tammy R Healy)\\nS...       0    alt.atheism\n",
       "3     From: capelli@vnet.IBM.COM (Ron Capelli)\\nSubj...       1  comp.graphics\n",
       "4     From: henry@zoo.toronto.edu (Henry Spencer)\\nS...       2      sci.space\n",
       "...                                                 ...     ...            ...\n",
       "1652  From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...       1  comp.graphics\n",
       "1653  From: renes@ecpdsharmony.cern.ch (Rene S. Dutc...       1  comp.graphics\n",
       "1654  From: xrcjd@resolve.gsfc.nasa.gov (Charles J. ...       2      sci.space\n",
       "1655  From: dietz@cs.rochester.edu (Paul Dietz)\\nSub...       2      sci.space\n",
       "1656  From: jhwitten@cs.ruu.nl (Jurriaan Wittenberg)...       2      sci.space\n",
       "\n",
       "[1657 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.load 20news group train subest\n",
    "train_subset=pd.read_csv(\"newsgroups_train.csv\")\n",
    "train_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a3cb27f5-1a46-4b56-83a5-96e82e39348b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: mccall@mksol.dseg.ti.com (fred j mccall ...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: \"Changyaw Wang\" &lt;wangc@cs.indiana.edu&gt;\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: lioness@maple.circa.ufl.edu\\nSubject: Te...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: hotopp@ami1.bwi.wec.com (Daniel T. Hotop...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: Ad-Robot@bobsbox.rent.com (Robotic Posti...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>From: malek@pi.titech.ac.jp (Zidouri Abdelmale...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>From: livesey@solntze.wpd.sgi.com (Jon Livesey...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>From: beck@irzr17.inf.tu-dresden.de (Andre Bec...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>From: 18084TM@msu.edu (Tom)\\nSubject: Billboar...</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1102 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target       category\n",
       "0     From: mccall@mksol.dseg.ti.com (fred j mccall ...       2      sci.space\n",
       "1     From: \"Changyaw Wang\" <wangc@cs.indiana.edu>\\n...       1  comp.graphics\n",
       "2     From: lioness@maple.circa.ufl.edu\\nSubject: Te...       1  comp.graphics\n",
       "3     From: hotopp@ami1.bwi.wec.com (Daniel T. Hotop...       1  comp.graphics\n",
       "4     From: Ad-Robot@bobsbox.rent.com (Robotic Posti...       1  comp.graphics\n",
       "...                                                 ...     ...            ...\n",
       "1097  From: malek@pi.titech.ac.jp (Zidouri Abdelmale...       1  comp.graphics\n",
       "1098  From: livesey@solntze.wpd.sgi.com (Jon Livesey...       0    alt.atheism\n",
       "1099  From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...       0    alt.atheism\n",
       "1100  From: beck@irzr17.inf.tu-dresden.de (Andre Bec...       1  comp.graphics\n",
       "1101  From: 18084TM@msu.edu (Tom)\\nSubject: Billboar...       2      sci.space\n",
       "\n",
       "[1102 rows x 3 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4.load 20news group train subest\n",
    "test_subset=pd.read_csv(\"newsgroups_test.csv\")\n",
    "test_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "09fc6960-0841-4da6-b002-8e7b2cb28adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All target labels in 20 Newsgroups dataset:\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "#5.print all # Load the dataset\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "\n",
    "# Print all target labels (categories)\n",
    "print(\"All target labels in 20 Newsgroups dataset:\")\n",
    "print(newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "82dc2f07-be43-47ad-bd7d-4410e4bbf168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected categories: ['alt.atheism', 'comp.graphics', 'sci.space']\n",
      "\n",
      "Sample Text from Training Data:\n",
      " \n",
      "  I doubt there are good prospects for  a self armoring system\n",
      "for venus surface conditions (several hundred degrees, very high\n",
      "pressure of CO2, possibly sulfuric and nitric acids or oxides\n",
      "but it is a notion to consider for outer planets rs where you might\n",
      "pick up ices under less extream upper atmosphere conditions buying\n",
      "deeper penetration.  A nice creative idea, unlikly but worthy of\n",
      "thinking about.\n",
      "\n",
      "\n",
      "Corresponding Label: 2\n"
     ]
    }
   ],
   "source": [
    "#6.prepare subset of categories alt.athessm com.graphics sci.space\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the dataset with the selected categories\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Print the categories to confirm the subset\n",
    "print(\"Selected categories:\", newsgroups_train.target_names)\n",
    "\n",
    "# Print some sample data and labels\n",
    "print(\"\\nSample Text from Training Data:\\n\", newsgroups_train.data[0])\n",
    "print(\"\\nCorresponding Label:\", newsgroups_train.target[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1936fcb3-5b7a-4968-bb56-2ea78c5c1812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded categories: ['alt.atheism', 'comp.graphics', 'sci.space']\n"
     ]
    }
   ],
   "source": [
    "#7 Load the training subset with selected categories\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Print the selected categories\n",
    "print(\"Loaded categories:\", newsgroups_train.target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2592c831-f58e-42f6-94e9-8ac5f7e369b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded categories: ['alt.atheism', 'comp.graphics', 'sci.space']\n"
     ]
    }
   ],
   "source": [
    "#8 Load the test subset with selected categories\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Print the selected categories\n",
    "print(\"Loaded categories:\", newsgroups_test.target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f5d0507f-e6f0-4c14-9915-682a518809fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New training set target names (labels): ['alt.atheism', 'comp.graphics', 'sci.space']\n",
      "Numerical labels assigned: {0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "#9.print new training set traget names(Lables)\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the training subset with selected categories\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Print the selected category labels\n",
    "print(\"New training set target names (labels):\", newsgroups_train.target_names)\n",
    "\n",
    "# Print unique numerical labels assigned to the categories\n",
    "print(\"Numerical labels assigned:\", set(newsgroups_train.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f1d1bdc0-4209-489d-b67d-e67c2f51f5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - 5th Article:\n",
      "\n",
      "\n",
      "I don't think you're going to be able to see the differences from a sphere\n",
      "unless they are greatly exaggerated.  Even the equatorial bulge is only\n",
      "about 1 part in 300 -- you'd never notice a 1mm error in a 30cm globe --\n",
      "and the other deviations from spherical shape are much smaller.\n",
      "\n",
      "Label of 5th Article: 2\n",
      "Category Name: sci.space\n"
     ]
    }
   ],
   "source": [
    "#10.print new training data of 5th article\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the training subset with selected categories\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Print the 5th article's text\n",
    "print(\"Training Data - 5th Article:\\n\")\n",
    "print(newsgroups_train.data[4])  # Index 4 (since indexing starts at 0)\n",
    "\n",
    "# Print the corresponding label of the 5th article\n",
    "print(\"\\nLabel of 5th Article:\", newsgroups_train.target[4])\n",
    "print(\"Category Name:\", newsgroups_train.target_names[newsgroups_train.target[4]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "49bcef5e-f32f-4286-b7f9-3af83fa7c77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: 1657\n",
      "Shape of training targets: 1657\n"
     ]
    }
   ],
   "source": [
    "#11.print the shape of data and targets\n",
    "print(\"Shape of training data:\", len(newsgroups_train.data))\n",
    "\n",
    "# Print the shape of the targets (number of labels)\n",
    "print(\"Shape of training targets:\", len(newsgroups_train.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "26f8fb34-f967-40de-aa1b-e2d7471252c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 training set filenames:\n",
      "['/home/user/scikit_learn_data/20news_home/20news-bydate-train/sci.space/60869'\n",
      " '/home/user/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38633'\n",
      " '/home/user/scikit_learn_data/20news_home/20news-bydate-train/alt.atheism/53534'\n",
      " '/home/user/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38516'\n",
      " '/home/user/scikit_learn_data/20news_home/20news-bydate-train/sci.space/61210']\n",
      "\n",
      "Total number of training files: 1657\n"
     ]
    }
   ],
   "source": [
    "#12. Print the first 5 filenames\n",
    "print(\"First 5 training set filenames:\")\n",
    "print(newsgroups_train.filenames[:5])\n",
    "\n",
    "# Print the total number of filenames\n",
    "print(\"\\nTotal number of training files:\", len(newsgroups_train.filenames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e0adb267-ca46-4cc7-ae91-cdd99adfebb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample transformed data (word count vector for first document):\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#13.by using count vectorizer train data into numerical format considering\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "categories=['alt.atheism', 'comp.graphics','sci.space']\n",
    "newsgroup_train=fetch_20newsgroups(subset=\"train\",categories=categories,remove=(\"headers\",\"footers\",\"quotes\"))\n",
    "vectorizer=CountVectorizer()\n",
    "X_train=vectorizer.fit_transform(newsgroup_train.data)\n",
    "print(\"\\nSample transformed data (word count vector for first document):\")\n",
    "print(X_train[0].toarray())  # Convert sparse matrix to dense array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6267d4a5-9755-44e9-bc3f-32bb9bf48ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7899818949909475\n"
     ]
    }
   ],
   "source": [
    "#14 Use bernoullNB for training\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "bnb=BernoulliNB()\n",
    "bnb.fit(X_train,newsgroup_train.target)\n",
    "y_pred=bnb.predict(X_train)\n",
    "accuracy= accuracy_score(newsgroup_train.target,y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ff7b570f-1ad9-485b-b5a8-a97c2248e987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of transformed test data (document-term matrix): (1102, 23598)\n",
      "\n",
      "Sample feature names: ['00' '000' '0000' '00000' '000000' '000005102000' '000062david42'\n",
      " '000100255pixel' '00041032' '0004136']\n",
      "\n",
      "Sample transformed test data (word count vector for first document):\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#15 By using countvectorizer convert test data into numeric format considering only\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the training and test subsets\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Initialize CountVectorizer and fit only on training data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train= vectorizer.fit_transform(newsgroups_train.data)  # Fit on training data\n",
    "\n",
    "# Transform test data using the same vocabulary\n",
    "X_test = vectorizer.transform(newsgroups_test.data)  # Transform test data\n",
    "\n",
    "# Print the shape of transformed test data\n",
    "print(\"Shape of transformed test data (document-term matrix):\", X_test.shape)\n",
    "\n",
    "# Print some feature names (words converted to features)\n",
    "print(\"\\nSample feature names:\", vectorizer.get_feature_names_out()[:10])\n",
    "\n",
    "# Print a sample row of the transformed test data\n",
    "print(\"\\nSample transformed test data (word count vector for first document):\")\n",
    "print(X_test[0].toarray())  # Convert sparse matrix to dense array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "56de96b8-2b69-4680-b85e-386f537eba11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted target labels for test set:\n",
      " [2 1 1 ... 0 1 2]\n",
      "\n",
      "Actual target labels:\n",
      " [2 1 1 ... 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "#16.Predict target labels for testing set\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the training and test subsets\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Convert text data into numerical format\n",
    "vectorizer = CountVectorizer(binary=True)  # Good for BernoulliNB\n",
    "X_train = vectorizer.fit_transform(newsgroups_train.data)\n",
    "X_test = vectorizer.transform(newsgroups_test.data)\n",
    "\n",
    "# Train the model\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, newsgroups_train.target)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = bnb.predict(X_test)\n",
    "\n",
    "# Print predicted vs actual\n",
    "print(\"Predicted target labels for test set:\\n\", y_pred)\n",
    "print(\"\\nActual target labels:\\n\", newsgroups_test.target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a35eb546-9a91-4585-9888-e5f61f769cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB Accuracy on test set: 0.6987295825771325\n"
     ]
    }
   ],
   "source": [
    "#17 Find the accuracy score on the test set\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(newsgroups_test.target, y_pred)\n",
    "print(\"BernoulliNB Accuracy on test set:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bfacd20e-2ab6-4a21-8742-6ad2cba43fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#18.Use TfidfVectorizer instead of count vectorizer and use multinomial NB\n",
    "from sklearn.datasets import fetch_20newsgroups \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the training and test subsets\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Convert text data into numerical format using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(newsgroups_train.data)  # Fit on training data\n",
    "X_test_tfidf = vectorizer.transform(newsgroups_test.data)  # Transform test data\n",
    "\n",
    "# Initialize and train the Multinomial Naïve Bayes classifier\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, newsgroups_train.target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "60d16c09-3cd0-4d5a-8385-ce4195805bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy using TfidfVectorizer & MultinomialNB: 0.8620689655172413\n"
     ]
    }
   ],
   "source": [
    "#19 Find test set accuracy\n",
    "y_pred = mnb.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(newsgroups_test.target, y_pred)\n",
    "print(\"Test set accuracy using TfidfVectorizer & MultinomialNB:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0d7721fe-f2ef-4e0d-ac49-07952825ce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy using TfidfVectorizer (with stopword removal) & MultinomialNB: 0.8729582577132486\n"
     ]
    }
   ],
   "source": [
    "#20 Try with avoiding stopwords and repet the same\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the subset of categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# Load the training and test subsets\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Convert text data into numerical format using TfidfVectorizer (with stopword removal)\n",
    "vectorizer = TfidfVectorizer(stop_words='english')  # Removes common stopwords like \"the\", \"is\", \"and\"\n",
    "X_train_tfidf = vectorizer.fit_transform(newsgroups_train.data)  # Fit on training data\n",
    "X_test_tfidf = vectorizer.transform(newsgroups_test.data)  # Transform test data\n",
    "\n",
    "# Initialize and train the Multinomial Naïve Bayes classifier\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, newsgroups_train.target)\n",
    "\n",
    "# Predict target labels for the test set\n",
    "y_pred = mnb.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(newsgroups_test.target, y_pred)\n",
    "print(\"Test set accuracy using TfidfVectorizer (with stopword removal) & MultinomialNB:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5b1381c7-4ec2-4a9c-9fa2-c47c8eaa990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=input\n",
    "#y=categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5616857a-eb51-41c5-8c2c-493c86f2013d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
